/**
 * Syst√®me de validation en continu avec suivi des progr√®s
 * Permet de valider automatiquement et de suivre l'√©volution de la pr√©cision
 */

import { HighVolumeValidator, HighVolumeConfig } from './HighVolumeValidator'
import { AdvancedReportingEngine, AdvancedAnalysis } from './AdvancedReporting'
import { ValidationResult, ValidationReport } from './ValidationEngine'
import * as fs from 'fs'
import * as path from 'path'
import { EventEmitter } from 'events'

export interface ContinuousValidationConfig {
  /** Configuration de validation haute performance */
  highVolumeConfig: HighVolumeConfig
  /** Fr√©quence de validation (en ms) */
  validationInterval: number
  /** Conditions de d√©clenchement automatique */
  triggers: {
    /** D√©clencher sur changement de code */
    onCodeChange: boolean
    /** D√©clencher √† intervalle fixe */
    onSchedule: boolean
    /** D√©clencher sur seuil de r√©gression */
    onRegressionThreshold: number // % de baisse d'accuracy
  }
  /** Configuration du suivi de progr√®s */
  progressTracking: {
    /** Historique √† conserver (nombre de runs) */
    historyLength: number
    /** M√©triques √† suivre */
    trackedMetrics: string[]
    /** Alertes */
    alerts: {
      accuracyThreshold: number
      regressionThreshold: number
      errorThreshold: number
    }
  }
}

export interface ValidationRun {
  id: string
  timestamp: Date
  trigger: 'manual' | 'scheduled' | 'code_change' | 'regression'
  config: HighVolumeConfig
  results: ValidationResult[]
  report: ValidationReport
  advancedAnalysis: AdvancedAnalysis
  metrics: ValidationMetrics
  duration: number
  status: 'success' | 'failed' | 'partial'
}

export interface ValidationMetrics {
  totalCases: number
  accuracy: number
  successRate: number
  averageError: number
  regressionFromLast?: number
  improvementAreas: string[]
  criticalIssues: string[]
}

export interface ProgressSnapshot {
  timestamp: Date
  runId: string
  accuracy: number
  successRate: number
  componentScores: Record<string, number>
  trends: {
    accuracy: 'improving' | 'stable' | 'declining'
    errorRate: 'improving' | 'stable' | 'declining'
  }
}

export class ContinuousValidationSystem extends EventEmitter {
  private config: ContinuousValidationConfig
  private validator: HighVolumeValidator
  private isRunning = false
  private intervalId?: NodeJS.Timeout
  private runHistory: ValidationRun[] = []
  private progressHistory: ProgressSnapshot[] = []
  private lastRunMetrics?: ValidationMetrics

  constructor(config: ContinuousValidationConfig) {
    super()
    this.config = config
    this.validator = new HighVolumeValidator(config.highVolumeConfig)
    this.loadHistoryFromDisk()
  }

  /**
   * D√©marre le syst√®me de validation en continu
   */
  async start(): Promise<void> {
    if (this.isRunning) {
      console.log('‚ö†Ô∏è  Le syst√®me de validation est d√©j√† en cours d\'ex√©cution')
      return
    }

    console.log('üöÄ D√©marrage du syst√®me de validation en continu...')
    this.isRunning = true

    // Validation initiale
    await this.runValidation('manual')

    // Configuration de la validation programm√©e
    if (this.config.triggers.onSchedule) {
      this.intervalId = setInterval(async () => {
        await this.runValidation('scheduled')
      }, this.config.validationInterval)
    }

    // TODO: Configuration de l'√©coute des changements de code
    if (this.config.triggers.onCodeChange) {
      this.setupCodeChangeWatcher()
    }

    this.emit('started')
    console.log('‚úÖ Syst√®me de validation en continu d√©marr√©')
  }

  /**
   * Arr√™te le syst√®me de validation en continu
   */
  async stop(): Promise<void> {
    if (!this.isRunning) return

    console.log('üõë Arr√™t du syst√®me de validation en continu...')
    this.isRunning = false

    if (this.intervalId) {
      clearInterval(this.intervalId)
      this.intervalId = undefined
    }

    // Sauvegarder l'historique
    await this.saveHistoryToDisk()

    this.emit('stopped')
    console.log('‚úÖ Syst√®me de validation en continu arr√™t√©')
  }

  /**
   * Lance une validation manuelle
   */
  async runValidation(
    trigger: 'manual' | 'scheduled' | 'code_change' | 'regression' = 'manual'
  ): Promise<ValidationRun> {
    const runId = `validation-${Date.now()}`
    const startTime = Date.now()

    console.log(`üîÑ D√©marrage de la validation ${runId} (trigger: ${trigger})`)
    this.emit('validation_started', { runId, trigger })

    try {
      // Ex√©cuter la validation haute performance
      const report = await this.validator.runHighVolumeValidation()
      
      // G√©n√©rer l'analyse avanc√©e
      const results = this.extractResultsFromReport(report)
      const advancedAnalysis = AdvancedReportingEngine.generateAdvancedAnalysis(results)
      
      // Calculer les m√©triques
      const metrics = this.calculateMetrics(results, report)
      
      // D√©tecter les r√©gressions
      const hasRegression = this.detectRegression(metrics)
      
      // Cr√©er le run
      const validationRun: ValidationRun = {
        id: runId,
        timestamp: new Date(),
        trigger,
        config: this.config.highVolumeConfig,
        results,
        report,
        advancedAnalysis,
        metrics,
        duration: Date.now() - startTime,
        status: 'success'
      }

      // Ajouter √† l'historique
      this.addRunToHistory(validationRun)
      
      // Cr√©er un snapshot de progr√®s
      this.createProgressSnapshot(validationRun)
      
      // Sauvegarder les r√©sultats
      await this.saveValidationRun(validationRun)
      
      // V√©rifier les alertes
      await this.checkAlerts(validationRun)
      
      // D√©clencher une validation de r√©gression si n√©cessaire
      if (hasRegression && trigger !== 'regression') {
        console.log('‚ö†Ô∏è  R√©gression d√©tect√©e, d√©clenchement d\'une validation de r√©gression...')
        setTimeout(() => this.runValidation('regression'), 5000)
      }

      this.emit('validation_completed', validationRun)
      console.log(`‚úÖ Validation ${runId} termin√©e avec succ√®s`)
      
      return validationRun

    } catch (error) {
      const failedRun: ValidationRun = {
        id: runId,
        timestamp: new Date(),
        trigger,
        config: this.config.highVolumeConfig,
        results: [],
        report: { summary: { totalTests: 0, passed: 0, failed: 0, errors: 0, averageAccuracy: 0 }, worstCases: [], criticalDifferences: [], recommendations: [] },
        advancedAnalysis: {} as AdvancedAnalysis,
        metrics: { totalCases: 0, accuracy: 0, successRate: 0, averageError: 0, improvementAreas: [], criticalIssues: [] },
        duration: Date.now() - startTime,
        status: 'failed'
      }

      this.emit('validation_failed', { runId, error })
      console.error(`‚ùå Validation ${runId} √©chou√©e:`, error)
      
      return failedRun
    }
  }

  /**
   * Extrait les r√©sultats du rapport de validation
   */
  private extractResultsFromReport(report: ValidationReport): ValidationResult[] {
    // Cette m√©thode d√©pend de l'impl√©mentation du rapport
    // Pour l'instant, retourner un tableau vide
    // TODO: Impl√©menter l'extraction des r√©sultats d√©taill√©s
    return []
  }

  /**
   * Calcule les m√©triques de validation
   */
  private calculateMetrics(results: ValidationResult[], report: ValidationReport): ValidationMetrics {
    const totalCases = report.summary.totalTests
    const accuracy = report.summary.averageAccuracy
    const successRate = (report.summary.passed / totalCases) * 100
    
    // Calculer l'erreur moyenne
    const averageError = results.length > 0
      ? results.reduce((sum, result) => sum + result.totalAbsoluteDifference, 0) / results.length
      : 0

    // Calculer la r√©gression par rapport au dernier run
    const regressionFromLast = this.lastRunMetrics
      ? accuracy - this.lastRunMetrics.accuracy
      : undefined

    // Identifier les domaines d'am√©lioration
    const improvementAreas = report.criticalDifferences
      .slice(0, 5)
      .map(diff => diff.field)

    // Identifier les probl√®mes critiques
    const criticalIssues = report.recommendations
      .filter(rec => rec.includes('critique') || rec.includes('urgent'))
      .slice(0, 3)

    const metrics: ValidationMetrics = {
      totalCases,
      accuracy,
      successRate,
      averageError,
      regressionFromLast,
      improvementAreas,
      criticalIssues
    }

    this.lastRunMetrics = metrics
    return metrics
  }

  /**
   * D√©tecte les r√©gressions de performance
   */
  private detectRegression(metrics: ValidationMetrics): boolean {
    if (!metrics.regressionFromLast) return false
    
    const regressionThreshold = this.config.triggers.onRegressionThreshold
    return metrics.regressionFromLast < -regressionThreshold
  }

  /**
   * Ajoute un run √† l'historique
   */
  private addRunToHistory(run: ValidationRun): void {
    this.runHistory.push(run)
    
    // Limiter la taille de l'historique
    if (this.runHistory.length > this.config.progressTracking.historyLength) {
      this.runHistory = this.runHistory.slice(-this.config.progressTracking.historyLength)
    }
  }

  /**
   * Cr√©e un snapshot de progr√®s
   */
  private createProgressSnapshot(run: ValidationRun): void {
    const componentScores: Record<string, number> = {}
    
    // Extraire les scores par composant
    run.advancedAnalysis.calculatorAnalysis?.components.forEach(component => {
      componentScores[component.name] = component.accuracy
    })

    // Calculer les tendances
    const trends = this.calculateTrends(run.metrics)

    const snapshot: ProgressSnapshot = {
      timestamp: run.timestamp,
      runId: run.id,
      accuracy: run.metrics.accuracy,
      successRate: run.metrics.successRate,
      componentScores,
      trends
    }

    this.progressHistory.push(snapshot)
    
    // Limiter la taille de l'historique de progr√®s
    if (this.progressHistory.length > this.config.progressTracking.historyLength) {
      this.progressHistory = this.progressHistory.slice(-this.config.progressTracking.historyLength)
    }
  }

  /**
   * Calcule les tendances de progr√®s
   */
  private calculateTrends(currentMetrics: ValidationMetrics): {
    accuracy: 'improving' | 'stable' | 'declining'
    errorRate: 'improving' | 'stable' | 'declining'
  } {
    if (this.progressHistory.length < 2) {
      return { accuracy: 'stable', errorRate: 'stable' }
    }

    const recentSnapshots = this.progressHistory.slice(-3)
    const accuracyTrend = this.calculateTrend(recentSnapshots.map(s => s.accuracy))
    const errorRateTrend = this.calculateTrend(recentSnapshots.map(s => 100 - s.successRate))

    return {
      accuracy: accuracyTrend,
      errorRate: errorRateTrend
    }
  }

  /**
   * Calcule la tendance d'une s√©rie de valeurs
   */
  private calculateTrend(values: number[]): 'improving' | 'stable' | 'declining' {
    if (values.length < 2) return 'stable'
    
    const firstHalf = values.slice(0, Math.floor(values.length / 2))
    const secondHalf = values.slice(Math.floor(values.length / 2))
    
    const firstAvg = firstHalf.reduce((sum, val) => sum + val, 0) / firstHalf.length
    const secondAvg = secondHalf.reduce((sum, val) => sum + val, 0) / secondHalf.length
    
    const difference = secondAvg - firstAvg
    
    if (Math.abs(difference) < 0.5) return 'stable'
    return difference > 0 ? 'improving' : 'declining'
  }

  /**
   * Sauvegarde un run de validation
   */
  private async saveValidationRun(run: ValidationRun): Promise<void> {
    const outputDir = this.config.highVolumeConfig.reporting.outputDir
    const runDir = path.join(outputDir, 'continuous-validation', run.id)
    
    if (!fs.existsSync(runDir)) {
      fs.mkdirSync(runDir, { recursive: true })
    }

    // Sauvegarder le run complet
    fs.writeFileSync(
      path.join(runDir, 'validation-run.json'),
      JSON.stringify(run, null, 2)
    )

    // Sauvegarder l'analyse avanc√©e
    AdvancedReportingEngine.saveAdvancedAnalysis(
      run.advancedAnalysis,
      path.join(runDir, 'advanced-analysis.json')
    )

    // G√©n√©rer le rapport HTML
    AdvancedReportingEngine.generateHTMLReport(
      run.advancedAnalysis,
      path.join(runDir, 'report.html')
    )

    console.log(`üíæ Run de validation sauv√©: ${runDir}`)
  }

  /**
   * V√©rifie les alertes et notifie si n√©cessaire
   */
  private async checkAlerts(run: ValidationRun): Promise<void> {
    const alerts = this.config.progressTracking.alerts
    const metrics = run.metrics

    // Alerte sur la pr√©cision
    if (metrics.accuracy < alerts.accuracyThreshold) {
      this.emit('alert', {
        type: 'accuracy',
        severity: 'high',
        message: `Pr√©cision faible: ${metrics.accuracy.toFixed(1)}% (seuil: ${alerts.accuracyThreshold}%)`,
        runId: run.id
      })
    }

    // Alerte sur la r√©gression
    if (metrics.regressionFromLast && Math.abs(metrics.regressionFromLast) > alerts.regressionThreshold) {
      this.emit('alert', {
        type: 'regression',
        severity: metrics.regressionFromLast < 0 ? 'high' : 'info',
        message: `Changement significatif: ${metrics.regressionFromLast > 0 ? '+' : ''}${metrics.regressionFromLast.toFixed(1)}%`,
        runId: run.id
      })
    }

    // Alerte sur les erreurs
    const errorRate = (run.report.summary.errors / run.report.summary.totalTests) * 100
    if (errorRate > alerts.errorThreshold) {
      this.emit('alert', {
        type: 'errors',
        severity: 'medium',
        message: `Taux d'erreur √©lev√©: ${errorRate.toFixed(1)}% (seuil: ${alerts.errorThreshold}%)`,
        runId: run.id
      })
    }
  }

  /**
   * Configuration de l'√©coute des changements de code
   */
  private setupCodeChangeWatcher(): void {
    // TODO: Impl√©menter avec fs.watch ou chokidar
    console.log('üîç Configuration de l\'√©coute des changements de code...')
    // Pour l'instant, juste un placeholder
  }

  /**
   * Charge l'historique depuis le disque
   */
  private loadHistoryFromDisk(): void {
    const historyPath = path.join(
      this.config.highVolumeConfig.reporting.outputDir,
      'continuous-validation',
      'history.json'
    )

    try {
      if (fs.existsSync(historyPath)) {
        const historyData = JSON.parse(fs.readFileSync(historyPath, 'utf-8'))
        this.runHistory = historyData.runs || []
        this.progressHistory = historyData.progress || []
        console.log(`üìÇ Historique charg√©: ${this.runHistory.length} runs, ${this.progressHistory.length} snapshots`)
      }
    } catch (error) {
      console.warn('‚ö†Ô∏è  Impossible de charger l\'historique:', error)
    }
  }

  /**
   * Sauvegarde l'historique sur le disque
   */
  private async saveHistoryToDisk(): Promise<void> {
    const historyPath = path.join(
      this.config.highVolumeConfig.reporting.outputDir,
      'continuous-validation',
      'history.json'
    )

    const historyDir = path.dirname(historyPath)
    if (!fs.existsSync(historyDir)) {
      fs.mkdirSync(historyDir, { recursive: true })
    }

    const historyData = {
      runs: this.runHistory,
      progress: this.progressHistory,
      lastUpdate: new Date()
    }

    fs.writeFileSync(historyPath, JSON.stringify(historyData, null, 2))
    console.log(`üíæ Historique sauv√©: ${historyPath}`)
  }

  /**
   * Obtient les statistiques de progr√®s
   */
  getProgressStats(): {
    totalRuns: number
    averageAccuracy: number
    trend: 'improving' | 'stable' | 'declining'
    lastRunMetrics?: ValidationMetrics
    recentIssues: string[]
  } {
    if (this.runHistory.length === 0) {
      return {
        totalRuns: 0,
        averageAccuracy: 0,
        trend: 'stable',
        recentIssues: []
      }
    }

    const accuracies = this.runHistory.map(run => run.metrics.accuracy)
    const averageAccuracy = accuracies.reduce((sum, acc) => sum + acc, 0) / accuracies.length
    const trend = this.calculateTrend(accuracies)

    // Collecter les probl√®mes r√©cents
    const recentIssues = this.runHistory
      .slice(-3)
      .flatMap(run => run.metrics.criticalIssues)
      .filter((issue, index, array) => array.indexOf(issue) === index) // D√©dupliquer

    return {
      totalRuns: this.runHistory.length,
      averageAccuracy,
      trend,
      lastRunMetrics: this.lastRunMetrics,
      recentIssues
    }
  }

  /**
   * G√©n√®re un rapport de progr√®s
   */
  generateProgressReport(): string {
    const stats = this.getProgressStats()
    
    let report = `
üìä RAPPORT DE PROGR√àS - VALIDATION CONTINUE
${'='.repeat(60)}

üìà Statistiques G√©n√©rales:
   ‚Ä¢ Nombre total de validations: ${stats.totalRuns}
   ‚Ä¢ Pr√©cision moyenne: ${stats.averageAccuracy.toFixed(1)}%
   ‚Ä¢ Tendance: ${stats.trend === 'improving' ? 'üìà En am√©lioration' : stats.trend === 'declining' ? 'üìâ En d√©clin' : '‚û°Ô∏è  Stable'}

`

    if (stats.lastRunMetrics) {
      report += `
üéØ Derni√®re Validation:
   ‚Ä¢ Pr√©cision: ${stats.lastRunMetrics.accuracy.toFixed(1)}%
   ‚Ä¢ Taux de succ√®s: ${stats.lastRunMetrics.successRate.toFixed(1)}%
   ‚Ä¢ Erreur moyenne: ${stats.lastRunMetrics.averageError.toFixed(0)}$
   ‚Ä¢ R√©gression: ${stats.lastRunMetrics.regressionFromLast ? (stats.lastRunMetrics.regressionFromLast > 0 ? '+' : '') + stats.lastRunMetrics.regressionFromLast.toFixed(1) + '%' : 'N/A'}

`
    }

    if (stats.recentIssues.length > 0) {
      report += `
‚ö†Ô∏è  Probl√®mes R√©cents:
${stats.recentIssues.map(issue => `   ‚Ä¢ ${issue}`).join('\n')}

`
    }

    if (this.progressHistory.length > 1) {
      const latest = this.progressHistory[this.progressHistory.length - 1]
      report += `
üîß Scores par Composant (dernier run):
${Object.entries(latest.componentScores)
  .map(([component, score]) => `   ‚Ä¢ ${component}: ${score.toFixed(1)}%`)
  .join('\n')}
`
    }

    return report
  }
}