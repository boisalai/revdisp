#!/usr/bin/env node

/**
 * Interface CLI pour le syst√®me de validation massive et continue
 */

import { Command } from 'commander'
import { MassTestGenerator, GeneratorConfig, GenerationStrategy } from './MassTestGenerator'
import { HighVolumeValidator, HighVolumeConfig } from './HighVolumeValidator'
import { ContinuousValidationSystem, ContinuousValidationConfig } from './ContinuousValidationSystem'
import { AdvancedReportingEngine } from './AdvancedReporting'
import * as fs from 'fs'
import * as path from 'path'

const program = new Command()

program
  .name('validation-cli')
  .description('CLI pour la validation massive du calculateur de revenu disponible')
  .version('1.0.0')

/**
 * Commande pour g√©n√©rer des cas de test en masse
 */
program
  .command('generate')
  .description('G√©n√®re des cas de test en masse')
  .option('-n, --count <number>', 'Nombre de cas √† g√©n√©rer', '1000')
  .option('-s, --strategy <type>', 'Strat√©gie de g√©n√©ration (systematic|random|grid|monte_carlo)', 'systematic')
  .option('-y, --year <number>', 'Ann√©e fiscale', '2024')
  .option('-o, --output <path>', 'Fichier de sortie', './generated-test-cases.json')
  .action(async (options) => {
    try {
      console.log('üè≠ G√©n√©ration de cas de test en masse...')
      
      const config: Partial<GeneratorConfig> = {
        totalCases: parseInt(options.count),
        taxYear: parseInt(options.year)
      }
      
      const strategy: GenerationStrategy = { type: options.strategy as any }
      const generator = new MassTestGenerator(config, strategy)
      
      const testCases = await generator.generateMassTestCases()
      
      // Sauvegarder les cas g√©n√©r√©s
      fs.writeFileSync(options.output, JSON.stringify(testCases, null, 2))
      
      console.log(`‚úÖ ${testCases.length} cas g√©n√©r√©s et sauv√©s dans ${options.output}`)
      
    } catch (error) {
      console.error('‚ùå Erreur lors de la g√©n√©ration:', error)
      process.exit(1)
    }
  })

/**
 * Commande pour lancer une validation haute performance
 */
program
  .command('validate')
  .description('Lance une validation haute performance')
  .option('-n, --count <number>', 'Nombre de cas √† valider', '1000')
  .option('-p, --parallel <number>', 'Nombre de navigateurs parall√®les', '3')
  .option('-b, --batch-size <number>', 'Taille des batches', '50')
  .option('-s, --strategy <type>', 'Strat√©gie de g√©n√©ration', 'systematic')
  .option('-o, --output <path>', 'R√©pertoire de sortie', './reports')
  .option('--resume <path>', 'Reprendre depuis un checkpoint')
  .action(async (options) => {
    try {
      console.log('üöÄ D√©marrage de la validation haute performance...')
      
      const config: HighVolumeConfig = {
        generator: {
          totalCases: parseInt(options.count),
          taxYear: 2024
        },
        generationStrategy: { type: options.strategy as any },
        scraping: {
          parallelBrowsers: parseInt(options.parallel),
          batchSize: parseInt(options.batchSize),
          batchDelay: 2000,
          resumeFromCheckpoint: options.resume,
          headless: true,
          timeout: 30000
        },
        reporting: {
          outputDir: options.output,
          saveIntermediate: true,
          checkpointFrequency: 5
        }
      }
      
      const validator = new HighVolumeValidator(config)
      const report = await validator.runHighVolumeValidation()
      
      console.log('üìä G√©n√©ration de l\'analyse avanc√©e...')
      const analysis = AdvancedReportingEngine.generateAdvancedAnalysis([])
      
      // Sauvegarder l'analyse
      const analysisPath = path.join(options.output, 'advanced-analysis.json')
      AdvancedReportingEngine.saveAdvancedAnalysis(analysis, analysisPath)
      
      // G√©n√©rer le rapport HTML
      const htmlPath = path.join(options.output, 'validation-report.html')
      AdvancedReportingEngine.generateHTMLReport(analysis, htmlPath)
      
      console.log(`‚úÖ Validation termin√©e. Rapports disponibles dans ${options.output}`)
      
    } catch (error) {
      console.error('‚ùå Erreur lors de la validation:', error)
      process.exit(1)
    }
  })

/**
 * Commande pour d√©marrer la validation continue
 */
program
  .command('continuous')
  .description('D√©marre le syst√®me de validation continue')
  .option('-i, --interval <number>', 'Intervalle entre validations (minutes)', '60')
  .option('-n, --count <number>', 'Nombre de cas par validation', '500')
  .option('-o, --output <path>', 'R√©pertoire de sortie', './continuous-reports')
  .option('--accuracy-threshold <number>', 'Seuil d\'alerte pr√©cision (%)', '85')
  .option('--regression-threshold <number>', 'Seuil d\'alerte r√©gression (%)', '5')
  .action(async (options) => {
    try {
      console.log('üîÑ D√©marrage du syst√®me de validation continue...')
      
      const config: ContinuousValidationConfig = {
        highVolumeConfig: {
          generator: {
            totalCases: parseInt(options.count),
            taxYear: 2024
          },
          generationStrategy: { type: 'random' },
          scraping: {
            parallelBrowsers: 2,
            batchSize: 25,
            batchDelay: 1000,
            headless: true,
            timeout: 30000
          },
          reporting: {
            outputDir: options.output,
            saveIntermediate: true,
            checkpointFrequency: 3
          }
        },
        validationInterval: parseInt(options.interval) * 60 * 1000, // Convertir en ms
        triggers: {
          onCodeChange: false, // TODO: impl√©menter
          onSchedule: true,
          onRegressionThreshold: parseFloat(options.regressionThreshold)
        },
        progressTracking: {
          historyLength: 50,
          trackedMetrics: ['accuracy', 'successRate', 'averageError'],
          alerts: {
            accuracyThreshold: parseFloat(options.accuracyThreshold),
            regressionThreshold: parseFloat(options.regressionThreshold),
            errorThreshold: 10
          }
        }
      }
      
      const system = new ContinuousValidationSystem(config)
      
      // Configurer les listeners d'√©v√©nements
      system.on('validation_started', (data) => {
        console.log(`üîÑ Validation d√©marr√©e: ${data.runId}`)
      })
      
      system.on('validation_completed', (run) => {
        console.log(`‚úÖ Validation termin√©e: ${run.id}`)
        console.log(`   üìä Pr√©cision: ${run.metrics.accuracy.toFixed(1)}%`)
        console.log(`   üìà Taux de succ√®s: ${run.metrics.successRate.toFixed(1)}%`)
        if (run.metrics.regressionFromLast) {
          const change = run.metrics.regressionFromLast > 0 ? '+' : ''
          console.log(`   üîÑ Changement: ${change}${run.metrics.regressionFromLast.toFixed(1)}%`)
        }
      })
      
      system.on('alert', (alert) => {
        console.log(`üö® ALERTE [${alert.type}]: ${alert.message}`)
      })
      
      // Gestion des signaux pour arr√™t propre
      process.on('SIGINT', async () => {
        console.log('\nüõë Arr√™t demand√©...')
        await system.stop()
        process.exit(0)
      })
      
      // D√©marrer le syst√®me
      await system.start()
      
      // Afficher le statut initial
      console.log('\nüìä Statut du syst√®me:')
      console.log(system.generateProgressReport())
      
      // Maintenir le processus actif
      console.log('üîÑ Syst√®me actif. Appuyez sur Ctrl+C pour arr√™ter.')
      await new Promise(() => {}) // Maintenir le processus
      
    } catch (error) {
      console.error('‚ùå Erreur dans la validation continue:', error)
      process.exit(1)
    }
  })

/**
 * Commande pour afficher le statut du syst√®me de validation continue
 */
program
  .command('status')
  .description('Affiche le statut de la validation continue')
  .option('-o, --output <path>', 'R√©pertoire des rapports', './continuous-reports')
  .action(async (options) => {
    try {
      const historyPath = path.join(options.output, 'continuous-validation', 'history.json')
      
      if (!fs.existsSync(historyPath)) {
        console.log('‚ÑπÔ∏è  Aucun historique de validation continue trouv√©')
        return
      }
      
      const historyData = JSON.parse(fs.readFileSync(historyPath, 'utf-8'))
      const runs = historyData.runs || []
      const progress = historyData.progress || []
      
      if (runs.length === 0) {
        console.log('‚ÑπÔ∏è  Aucun run de validation trouv√©')
        return
      }
      
      const lastRun = runs[runs.length - 1]
      const successfulRuns = runs.filter((r: any) => r.status === 'success')
      const averageAccuracy = successfulRuns.reduce((sum: number, r: any) => sum + r.metrics.accuracy, 0) / successfulRuns.length
      
      console.log('üìä STATUT DE LA VALIDATION CONTINUE')
      console.log('='.repeat(50))
      console.log(`üèÉ Nombre total de runs: ${runs.length}`)
      console.log(`‚úÖ Runs r√©ussis: ${successfulRuns.length}`)
      console.log(`üìà Pr√©cision moyenne: ${averageAccuracy.toFixed(1)}%`)
      console.log(`üïí Dernier run: ${new Date(lastRun.timestamp).toLocaleString('fr-CA')}`)
      console.log(`üéØ Pr√©cision du dernier run: ${lastRun.metrics.accuracy.toFixed(1)}%`)
      
      if (lastRun.metrics.regressionFromLast) {
        const change = lastRun.metrics.regressionFromLast > 0 ? '+' : ''
        console.log(`üìä Changement depuis le run pr√©c√©dent: ${change}${lastRun.metrics.regressionFromLast.toFixed(1)}%`)
      }
      
      if (progress.length > 1) {
        const recentProgress = progress.slice(-5)
        console.log('\nüìà Progr√®s r√©cent (5 derniers snapshots):')
        recentProgress.forEach((snapshot: any) => {
          console.log(`   ${new Date(snapshot.timestamp).toLocaleDateString('fr-CA')}: ${snapshot.accuracy.toFixed(1)}%`)
        })
      }
      
    } catch (error) {
      console.error('‚ùå Erreur lors de la lecture du statut:', error)
      process.exit(1)
    }
  })

/**
 * Commande pour analyser un rapport de validation existant
 */
program
  .command('analyze')
  .description('Analyse un rapport de validation existant')
  .option('-f, --file <path>', 'Fichier de rapport JSON √† analyser', './validation-report.json')
  .option('-o, --output <path>', 'R√©pertoire de sortie pour l\'analyse', './analysis')
  .action(async (options) => {
    try {
      if (!fs.existsSync(options.file)) {
        console.error(`‚ùå Fichier non trouv√©: ${options.file}`)
        process.exit(1)
      }
      
      console.log(`üìä Analyse du rapport: ${options.file}`)
      
      // Charger le rapport
      const reportData = JSON.parse(fs.readFileSync(options.file, 'utf-8'))
      
      // TODO: Extraire les r√©sultats du rapport selon son format
      const results: any[] = [] // Placeholder
      
      // G√©n√©rer l'analyse avanc√©e
      const analysis = AdvancedReportingEngine.generateAdvancedAnalysis(results)
      
      // Cr√©er le r√©pertoire de sortie
      if (!fs.existsSync(options.output)) {
        fs.mkdirSync(options.output, { recursive: true })
      }
      
      // Sauvegarder l'analyse
      AdvancedReportingEngine.saveAdvancedAnalysis(
        analysis,
        path.join(options.output, 'advanced-analysis.json')
      )
      
      // G√©n√©rer le rapport HTML
      AdvancedReportingEngine.generateHTMLReport(
        analysis,
        path.join(options.output, 'analysis-report.html')
      )
      
      console.log(`‚úÖ Analyse termin√©e. R√©sultats dans ${options.output}`)
      
    } catch (error) {
      console.error('‚ùå Erreur lors de l\'analyse:', error)
      process.exit(1)
    }
  })

// Gestion des erreurs non captur√©es
process.on('unhandledRejection', (reason, promise) => {
  console.error('‚ùå Rejection non g√©r√©e:', reason)
  process.exit(1)
})

process.on('uncaughtException', (error) => {
  console.error('‚ùå Exception non g√©r√©e:', error)
  process.exit(1)
})

// Parser les arguments de la ligne de commande
program.parse(process.argv)

export { program }